{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"合作委员会\"\n",
    "tokens = tokenizer.tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['合', '作', '委', '员', '会']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('合作', 'verb'), ('委员会', 'noun')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pynlpir as pp\n",
    "pp.open()\n",
    "example = \"合作委员会\"\n",
    "\n",
    "pp.segment(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = '历史和地理'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('历史', 'noun'), ('和', 'conjunction'), ('地理', 'noun')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented = pp.segment(word)\n",
    "segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'ini': 0, 'end': 2}, 1: {'ini': 2, 'end': 3}, 2: {'ini': 3, 'end': 5}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_ind = {}\n",
    "for i in range(len(segmented)):\n",
    "    print(i)\n",
    "    if i==0:\n",
    "        seg_ind[i] = {'ini': 0,'end':len(segmented[i][0])}\n",
    "    else:\n",
    "        ini = seg_ind[i-1]['end']\n",
    "        seg_ind[i] = {'ini':ini,'end':ini+len(segmented[i][0])}\n",
    "seg_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = '历史和地理'\n",
    "token = nlp(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "历史 NOUN\n",
      "和 CCONJ\n",
      "地理 NOUN\n"
     ]
    }
   ],
   "source": [
    "for t in token:\n",
    "    print(t.text, t.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token[0].pos_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seg2dict(segmented):\n",
    "#     seg_ind = {}\n",
    "#     for i in range(len(segmented)):\n",
    "#         if i==0:\n",
    "#             seg_ind[i] = {'ini': 0,'end':len(segmented[i][0])}\n",
    "#         else:\n",
    "#             ini = seg_ind[i-1]['end']\n",
    "#             seg_ind[i] = {'ini':ini,'end':ini+len(segmented[i][0])}\n",
    "#     return seg_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def char2features(word, i):\n",
    "#     '''\n",
    "#     pynlpir\n",
    "    \n",
    "#     word: whole word\n",
    "#     i: index of character\n",
    "    \n",
    "#     return features\n",
    "#         where features is a dictionary containing:\n",
    "#             char: target character\n",
    "#     '''å\n",
    "#     segmented = pp.segment(word)\n",
    "#     seg_ind = seg2dict(segmented)\n",
    "    \n",
    "# #     print(word)\n",
    "# #     print(seg_ind, i)\n",
    "    \n",
    "    \n",
    "#     for k in seg_ind.keys():\n",
    "#         end = seg_ind[k]['end']\n",
    "#         if i < end:\n",
    "#             seg_word = segmented[k][0]\n",
    "#             ini = seg_ind[k]['ini']\n",
    "#             posInSeg = i - ini\n",
    "#             POS_seg = segmented[k][1]\n",
    "#             break\n",
    "    \n",
    "#     if i >= end:\n",
    "#         seg_end = end\n",
    "#         seg_word = word[seg_end:]\n",
    "#         posInSeg = i - seg_end\n",
    "#         POS_seg = \"noun\"\n",
    "    \n",
    "#     features = {\n",
    "#         'bias': 1.0,\n",
    "#         'char': word[i],\n",
    "#         'i': i,\n",
    "#         'word length': len(word),\n",
    "#         'segment': seg_word,\n",
    "#         'position in seg': posInSeg,\n",
    "#         'POS of seg': POS_seg\n",
    "        \n",
    "#     }\n",
    "    \n",
    "#     # previous char info\n",
    "#     if i > 0:\n",
    "#         features['Prev'] = word[i-1]\n",
    "#         if i > 1:\n",
    "#             features['Prev2'] = word[i-2]\n",
    "#         else:\n",
    "#             features['Prev2'] = \"None\"\n",
    "#     else:\n",
    "#         features.update({\n",
    "#             'Prev': \"None\",\n",
    "#             'Prev2': \"None\"\n",
    "#         })\n",
    "    \n",
    "#     # post char info\n",
    "#     if i < len(word)-1:\n",
    "#         features['Post'] = word[i+1]\n",
    "#         if i < len(word)-2:\n",
    "#             features['Post2'] = word[i+2]\n",
    "#         else:\n",
    "#             features['Post2'] = \"None\"\n",
    "#     else:\n",
    "#         features.update({\n",
    "#             'Post': \"None\",\n",
    "#             'Post2': \"None\"\n",
    "#         })\n",
    "        \n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg2dict(segmented):\n",
    "    seg_ind = {}\n",
    "    for i,t in enumerate(segmented):\n",
    "        if i==0:\n",
    "            seg_ind[i] = {'ini': 0,'end':len(segmented[i].text)}\n",
    "        else:\n",
    "            ini = seg_ind[i-1]['end']\n",
    "            seg_ind[i] = {'ini':ini,'end':ini+len(segmented[i].text)}\n",
    "    return seg_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char2features(word, i):\n",
    "    '''\n",
    "    SPACY\n",
    "    \n",
    "    word: whole word\n",
    "    i: index of character\n",
    "    \n",
    "    return features\n",
    "        where features is a dictionary containing:\n",
    "            char: target character\n",
    "    '''\n",
    "    segmented = nlp(word)\n",
    "    seg_ind = seg2dict(segmented)\n",
    "    \n",
    "#     print(word)\n",
    "#     print(seg_ind, i)\n",
    "    \n",
    "    \n",
    "    for k in seg_ind.keys():\n",
    "        end = seg_ind[k]['end']\n",
    "        if i < end:\n",
    "            seg_word = segmented[k].text\n",
    "            ini = seg_ind[k]['ini']\n",
    "            posInSeg = i - ini\n",
    "            POS_seg = segmented[k].pos_\n",
    "            break\n",
    "    \n",
    "#     if i >= end:\n",
    "#         seg_end = end\n",
    "#         seg_word = word[seg_end:]\n",
    "#         posInSeg = i - seg_end\n",
    "#         POS_seg = \"noun\"\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'char': word[i],\n",
    "        'i': i,\n",
    "        'word length': len(word),\n",
    "        'segment': seg_word,\n",
    "        'position in seg': posInSeg,\n",
    "        'POS of seg': POS_seg\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # previous char info\n",
    "    if i > 0:\n",
    "        features['Prev'] = word[i-1]\n",
    "        if i > 1:\n",
    "            features['Prev2'] = word[i-2]\n",
    "        else:\n",
    "            features['Prev2'] = \"None\"\n",
    "    else:\n",
    "        features.update({\n",
    "            'Prev': \"None\",\n",
    "            'Prev2': \"None\"\n",
    "        })\n",
    "    \n",
    "    # post char info\n",
    "    if i < len(word)-1:\n",
    "        features['Post'] = word[i+1]\n",
    "        if i < len(word)-2:\n",
    "            features['Post2'] = word[i+2]\n",
    "        else:\n",
    "            features['Post2'] = \"None\"\n",
    "    else:\n",
    "        features.update({\n",
    "            'Post': \"None\",\n",
    "            'Post2': \"None\"\n",
    "        })\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'char': '和',\n",
       " 'i': 2,\n",
       " 'word length': 5,\n",
       " 'segment': '和',\n",
       " 'position in seg': 0,\n",
       " 'POS of seg': 'CCONJ',\n",
       " 'Prev': '史',\n",
       " 'Prev2': '历',\n",
       " 'Post': '地',\n",
       " 'Post2': '理'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2features(word, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(word):\n",
    "    return [char2features(word, i) for i in range(len(word))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cleaned_AbbOri = pickle.load(open('Cleaned_AbbOri_tr.p','rb'))\n",
    "Tagged_Abb = pickle.load(open('Tagged_tr.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['史地', '历史和地理'],\n",
       " ['正选', '正式选举'],\n",
       " ['营运', '营业运行'],\n",
       " ['n', '尼亚加拉瀑布'],\n",
       " ['粮播', '粮食播种']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_AbbOri[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagged_Abb[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [ word2features(word) for _, word in cleaned_AbbOri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'char': '铁',\n",
       "  'i': 0,\n",
       "  'word length': 5,\n",
       "  'segment': '铁路',\n",
       "  'position in seg': 0,\n",
       "  'POS of seg': 'NOUN',\n",
       "  'Prev': 'None',\n",
       "  'Prev2': 'None',\n",
       "  'Post': '路',\n",
       "  'Post2': '委'},\n",
       " {'bias': 1.0,\n",
       "  'char': '路',\n",
       "  'i': 1,\n",
       "  'word length': 5,\n",
       "  'segment': '铁路',\n",
       "  'position in seg': 1,\n",
       "  'POS of seg': 'NOUN',\n",
       "  'Prev': '铁',\n",
       "  'Prev2': 'None',\n",
       "  'Post': '委',\n",
       "  'Post2': '员'},\n",
       " {'bias': 1.0,\n",
       "  'char': '委',\n",
       "  'i': 2,\n",
       "  'word length': 5,\n",
       "  'segment': '委员会',\n",
       "  'position in seg': 0,\n",
       "  'POS of seg': 'NOUN',\n",
       "  'Prev': '路',\n",
       "  'Prev2': '铁',\n",
       "  'Post': '员',\n",
       "  'Post2': '会'},\n",
       " {'bias': 1.0,\n",
       "  'char': '员',\n",
       "  'i': 3,\n",
       "  'word length': 5,\n",
       "  'segment': '委员会',\n",
       "  'position in seg': 1,\n",
       "  'POS of seg': 'NOUN',\n",
       "  'Prev': '委',\n",
       "  'Prev2': '路',\n",
       "  'Post': '会',\n",
       "  'Post2': 'None'},\n",
       " {'bias': 1.0,\n",
       "  'char': '会',\n",
       "  'i': 4,\n",
       "  'word length': 5,\n",
       "  'segment': '委员会',\n",
       "  'position in seg': 2,\n",
       "  'POS of seg': 'NOUN',\n",
       "  'Prev': '员',\n",
       "  'Prev2': '委',\n",
       "  'Post': 'None',\n",
       "  'Post2': 'None'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2label(word):\n",
    "    return [l for _, l in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N', 'A', 'N', 'A', 'N']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = [word2label(word) for word in Tagged_Abb]\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_AbbOri_te = pickle.load(open('Cleaned_AbbOri_te.p','rb'))\n",
    "Tagged_Abb_te = pickle.load(open('Tagged_te.p','rb'))\n",
    "x_test = [word2features(word) for _, word in cleaned_AbbOri_te]\n",
    "y_test = [word2label(word) for word in Tagged_Abb_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagged_Abb_te[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(x_train, open(\"x_train_crf_spacy.p\", \"wb\"))\n",
    "pickle.dump(y_train, open(\"y_train_crf_spacy.p\", \"wb\"))\n",
    "pickle.dump(x_test, open(\"x_test_crf_spacy.p\", \"wb\"))\n",
    "pickle.dump(y_test, open(\"y_test_crf_spacy.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kazuyabe/.pyenv/versions/3.8.3/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N', 'A']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8319406138664762"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(x_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925707507620848"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(x_train)\n",
    "metrics.flat_f1_score(y_train, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
